{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquetta = [ x for x in (Path('data')/'compressed').iterdir() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:24<00:00, 14.83it/s]\n"
     ]
    }
   ],
   "source": [
    "header_options = dict()\n",
    "for file in tqdm(parquetta):\n",
    "    df = pd.read_parquet(file)\n",
    "    header_str = str(df.columns.values)\n",
    "    if header_str not in header_options:\n",
    "        header_options[header_str] = list()\n",
    "    header_options[header_str].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rental Id' 'Duration' 'Bike Id' 'End Date' 'EndStation Id'\n",
      " 'EndStation Name' 'Start Date' 'StartStation Id' 'StartStation Name'] 345\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Rental Id' 'Duration' 'Bike Id' 'End Date' 'EndStation Id'\n",
      " 'EndStation Name' 'Start Date' 'StartStation Id' 'StartStation Name'\n",
      " 'Unnamed: 9' 'Unnamed: 10'] 2\n",
      "data\\compressed\\05JourneyDataExtract01May2016-17May2016.parquet\n",
      "data\\compressed\\15JourneyDataExtract20Jul2016-26Jul2016.parquet\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Rental Id' 'Duration' 'Bike Id' 'End Date' 'EndStation Id'\n",
      " 'EndStation Name' 'Start Date' 'StartStation Id' 'StartStation Name'\n",
      " 'Unnamed: 9' 'Unnamed: 10' 'Unnamed: 11'] 8\n",
      "data\\compressed\\06JourneyDataExtract18May2016-24May2016.parquet\n",
      "data\\compressed\\07JourneyDataExtract25May2016-31May2016.parquet\n",
      "data\\compressed\\08JourneyDataExtract01Jun2016-07Jun2016.parquet\n",
      "data\\compressed\\09JourneyDataExtract08Jun2016-14Jun2016.parquet\n",
      "data\\compressed\\11JourneyDataExtract22Jun2016-28Jun2016.parquet\n",
      "data\\compressed\\12JourneyDataExtract29Jun2016-05Jul2016.parquet\n",
      "data\\compressed\\14JourneyDataExtract13Jul2016-19Jul2016.parquet\n",
      "data\\compressed\\16JourneyDataExtract27Jul2016-02Aug2016.parquet\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Rental Id' 'Duration' 'Bike Id' 'End Date' 'EndStation Logical Terminal'\n",
      " 'EndStation Name' 'endStationPriority_id' 'Start Date'\n",
      " 'StartStation Logical Terminal' 'StartStation Name'] 1\n",
      "data\\compressed\\21JourneyDataExtract31Aug2016-06Sep2016.parquet\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Rental Id' 'Duration' 'Bike Id' 'End Date' 'EndStation Name'\n",
      " 'Start Date' 'StartStation Id' 'StartStation Name'] 1\n",
      "data\\compressed\\325JourneyDataExtract06Jul2022-12Jul2022.parquet\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Rental Id' 'Duration_Seconds' 'Bike Id' 'End Date' 'End Station Id'\n",
      " 'End Station Name' 'Start Date' 'Start Station Id' 'Start Station Name'] 6\n",
      "data\\compressed\\73JourneyDataExtract30Aug2017-05Sep2017.parquet\n",
      "data\\compressed\\74JourneyDataExtract06Sep2017-12Sep2017.parquet\n",
      "data\\compressed\\75JourneyDataExtract13Sep2017-19Sep2017.parquet\n",
      "data\\compressed\\79JourneyDataExtract11Oct2017-17Oct2017.parquet\n",
      "data\\compressed\\80JourneyDataExtract18Oct2017-24Oct2017.parquet\n",
      "data\\compressed\\81JourneyDataExtract25Oct2017-31Oct2017.parquet\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for k,v in header_options.items():\n",
    "    print(k,len(v))\n",
    "    if len(v) < 10:\n",
    "        for err in v:\n",
    "            print(str(err))\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "---\n",
    "- We should drop data\\compressed\\21JourneyDataExtract31Aug2016-06Sep2016.parquet, as it is really hard to convert, becauses the station id-s are missinb, but reductable\n",
    "- We shoud drop data\\compressed\\325JourneyDataExtract06Jul2022-12Jul2022.parquet as there the end station id is missing, but reductable\n",
    "- Others could be transformed to the original data shape\n",
    "\n",
    "\n",
    "Mappings:\n",
    "---\n",
    "- `Start Station Name` => `StartStation Name`\n",
    "- `Start Station Id` => `StartStation Id`\n",
    "- `End Station Name` => `EndStation Name`\n",
    "- `End Station Id` => `EndStation Id`\n",
    "- `Duration_Seconds` => `Duration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "'Start Station Name': 'StartStation Name',\n",
    "'Start Station Id': 'StartStation Id',\n",
    "'End Station Name': 'EndStation Name',\n",
    "'End Station Id': 'EndStation Id',\n",
    "'Duration_Seconds': 'Duration',\n",
    "}\n",
    "\n",
    "unused_fields = [\n",
    "    'Unnamed: 9',\n",
    "    'Unnamed: 10',\n",
    "    'Unnamed: 11',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified  data\\compressed\\05JourneyDataExtract01May2016-17May2016.parquet Reasons {} ['Unnamed: 9', 'Unnamed: 10']\n",
      "Modified  data\\compressed\\15JourneyDataExtract20Jul2016-26Jul2016.parquet Reasons {} ['Unnamed: 9', 'Unnamed: 10']\n",
      "Modified  data\\compressed\\06JourneyDataExtract18May2016-24May2016.parquet Reasons {} ['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11']\n",
      "Modified  data\\compressed\\07JourneyDataExtract25May2016-31May2016.parquet Reasons {} ['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11']\n",
      "Modified  data\\compressed\\08JourneyDataExtract01Jun2016-07Jun2016.parquet Reasons {} ['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11']\n",
      "Modified  data\\compressed\\09JourneyDataExtract08Jun2016-14Jun2016.parquet Reasons {} ['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11']\n",
      "Modified  data\\compressed\\11JourneyDataExtract22Jun2016-28Jun2016.parquet Reasons {} ['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11']\n",
      "Modified  data\\compressed\\12JourneyDataExtract29Jun2016-05Jul2016.parquet Reasons {} ['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11']\n",
      "Modified  data\\compressed\\14JourneyDataExtract13Jul2016-19Jul2016.parquet Reasons {} ['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11']\n",
      "Modified  data\\compressed\\16JourneyDataExtract27Jul2016-02Aug2016.parquet Reasons {} ['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11']\n",
      "Modified  data\\compressed\\73JourneyDataExtract30Aug2017-05Sep2017.parquet Reasons {'Start Station Name': 'StartStation Name', 'Start Station Id': 'StartStation Id', 'End Station Name': 'EndStation Name', 'End Station Id': 'EndStation Id', 'Duration_Seconds': 'Duration'} []\n",
      "Modified  data\\compressed\\74JourneyDataExtract06Sep2017-12Sep2017.parquet Reasons {'Start Station Name': 'StartStation Name', 'Start Station Id': 'StartStation Id', 'End Station Name': 'EndStation Name', 'End Station Id': 'EndStation Id', 'Duration_Seconds': 'Duration'} []\n",
      "Modified  data\\compressed\\75JourneyDataExtract13Sep2017-19Sep2017.parquet Reasons {'Start Station Name': 'StartStation Name', 'Start Station Id': 'StartStation Id', 'End Station Name': 'EndStation Name', 'End Station Id': 'EndStation Id', 'Duration_Seconds': 'Duration'} []\n",
      "Modified  data\\compressed\\79JourneyDataExtract11Oct2017-17Oct2017.parquet Reasons {'Start Station Name': 'StartStation Name', 'Start Station Id': 'StartStation Id', 'End Station Name': 'EndStation Name', 'End Station Id': 'EndStation Id', 'Duration_Seconds': 'Duration'} []\n",
      "Modified  data\\compressed\\80JourneyDataExtract18Oct2017-24Oct2017.parquet Reasons {'Start Station Name': 'StartStation Name', 'Start Station Id': 'StartStation Id', 'End Station Name': 'EndStation Name', 'End Station Id': 'EndStation Id', 'Duration_Seconds': 'Duration'} []\n",
      "Modified  data\\compressed\\81JourneyDataExtract25Oct2017-31Oct2017.parquet Reasons {'Start Station Name': 'StartStation Name', 'Start Station Id': 'StartStation Id', 'End Station Name': 'EndStation Name', 'End Station Id': 'EndStation Id', 'Duration_Seconds': 'Duration'} []\n"
     ]
    }
   ],
   "source": [
    "for k,v in header_options.items():\n",
    "    #load files\n",
    "    for file in v:\n",
    "        df = pd.read_parquet(file)\n",
    "        rename_policy = {k:v for k,v in mapping.items() if k in df.columns.values}\n",
    "        droppable = [f for f in unused_fields if f in df.columns.values]\n",
    "        if not rename_policy and not droppable: #empty dict, no work to do here\n",
    "            continue\n",
    "        if rename_policy:\n",
    "           df.rename(columns=rename_policy,inplace=True)\n",
    "        if droppable:\n",
    "            df.drop(columns=droppable,inplace=True)\n",
    "        print(\"Modified \",file, \"Reasons\",rename_policy,droppable)\n",
    "        og_file = file\n",
    "        file.rename(file.parent /(file.name+'.bak'))\n",
    "        df.to_parquet(og_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mismatched_headers():\n",
    "    header_options = dict()\n",
    "    for file in tqdm(parquetta):\n",
    "        df = pd.read_parquet(file)\n",
    "        header_str = str(df.columns.values)\n",
    "        if header_str not in header_options:\n",
    "            header_options[header_str] = list()\n",
    "        header_options[header_str].append(file)\n",
    "    for k,v in header_options.items():\n",
    "        print(k,len(v))\n",
    "        if len(v) < 10:\n",
    "            for err in v:\n",
    "                print(str(err))\n",
    "        print('-'*100)\n",
    "    return header_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:22<00:00, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rental Id' 'Duration' 'Bike Id' 'End Date' 'EndStation Id'\n",
      " 'EndStation Name' 'Start Date' 'StartStation Id' 'StartStation Name'] 361\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Rental Id' 'Duration' 'Bike Id' 'End Date' 'EndStation Logical Terminal'\n",
      " 'EndStation Name' 'endStationPriority_id' 'Start Date'\n",
      " 'StartStation Logical Terminal' 'StartStation Name'] 1\n",
      "data\\compressed\\21JourneyDataExtract31Aug2016-06Sep2016.parquet\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Rental Id' 'Duration' 'Bike Id' 'End Date' 'EndStation Name'\n",
      " 'Start Date' 'StartStation Id' 'StartStation Name'] 1\n",
      "data\\compressed\\325JourneyDataExtract06Jul2022-12Jul2022.parquet\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = check_mismatched_headers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = sorted(results.items(),key=lambda x:len(x[1]))[-1][1]\n",
    "selected = [ str(x) for x in selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('correct_files.json','w+') as jfile:\n",
    "    json.dump(selected,jfile,indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39e94e8b32935e3ce89ecef5d29ce986d9cae3d7052e32946fbf3b05ec2f28a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
