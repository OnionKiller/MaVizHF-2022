{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all accessible cyceling data from tfl.gov.uk S3 buckets3s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "from botocore.handlers import disable_signing\n",
    "from pathlib import Path\n",
    "\n",
    "#s3 = boto3.client('s3',config=Config(signature_version=UNSIGNED))\n",
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.meta.events.register('choose-signer.s3.*', disable_signing)\n",
    "\n",
    "tfl_bucket = s3.Bucket('cycling.data.tfl.gov.uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acl', 'Cors', 'Lifecycle', 'LifecycleConfiguration', 'Logging', 'Notification', 'Object', 'Policy', 'RequestPayment', 'Tagging', 'Versioning', 'Website']\n"
     ]
    }
   ],
   "source": [
    "print(tfl_bucket.get_available_subresources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "for res in tfl_bucket.objects.filter(Prefix='usage-stats/'):\n",
    "    print(res.key,res.key.split('/')[-1])\n",
    "    try:\n",
    "        path = Path('data') / Path(res.key.split('/')[-1])\n",
    "        print(\"Save to\",path)\n",
    "        tfl_bucket.download_file(res.key,str(path))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as ddf\n",
    "from tqdm.dask import TqdmCallback\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [ x for x in Path('data').iterdir() if x.suffix == '.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [08:46<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(files):\n",
    "    df = pd.read_csv(file)\n",
    "    df.to_parquet(Path('data')/Path('compressed')/Path(file.stem+'.parquet'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquetta = [ x for x in (Path('data')/'compressed').iterdir() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [01:11<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "df_list = list()\n",
    "for file in tqdm(parquetta):\n",
    "    df_list.append(pd.read_parquet(file))\n",
    "gdf = pd.concat(df_list)\n",
    "print(not gdf['Rental Id'].is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1626367100\n"
     ]
    }
   ],
   "source": [
    "print(gdf.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['Start Date'] = pd.to_datetime(gdf['Start Date'],exact=False,infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dgdf \u001b[39m=\u001b[39m ddf\u001b[39m.\u001b[39;49mfrom_pandas(gdf,\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\dataframe\\io\\io.py:275\u001b[0m, in \u001b[0;36mfrom_pandas\u001b[1;34m(data, npartitions, chunksize, sort, name)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunksize, \u001b[39mint\u001b[39m):\n\u001b[0;32m    271\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    272\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease provide chunksize as an int, or possibly as None if you specify npartitions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     )\n\u001b[1;32m--> 275\u001b[0m name \u001b[39m=\u001b[39m name \u001b[39mor\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mfrom_pandas-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m tokenize(data, chunksize, npartitions))\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nrows:\n\u001b[0;32m    278\u001b[0m     \u001b[39mreturn\u001b[39;00m new_dd_object({(name, \u001b[39m0\u001b[39m): data}, name, data, [\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m])\n",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\base.py:931\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    923\u001b[0m     \u001b[39m\"\"\"Deterministic token\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \n\u001b[0;32m    925\u001b[0m \u001b[39m    >>> tokenize([1, 2, '3'])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[39m    True\u001b[39;00m\n\u001b[0;32m    930\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 931\u001b[0m     hasher \u001b[39m=\u001b[39m _md5(\u001b[39mstr\u001b[39m(\u001b[39mtuple\u001b[39;49m(\u001b[39mmap\u001b[39;49m(normalize_token, args)))\u001b[39m.\u001b[39mencode())\n\u001b[0;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m kwargs:\n\u001b[0;32m    933\u001b[0m         hasher\u001b[39m.\u001b[39mupdate(\u001b[39mstr\u001b[39m(normalize_token(kwargs))\u001b[39m.\u001b[39mencode())\n",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\utils.py:640\u001b[0m, in \u001b[0;36mDispatch.__call__\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[39mCall the corresponding method based on type of argument.\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    639\u001b[0m meth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch(\u001b[39mtype\u001b[39m(arg))\n\u001b[1;32m--> 640\u001b[0m \u001b[39mreturn\u001b[39;00m meth(arg, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\base.py:1157\u001b[0m, in \u001b[0;36mregister_pandas.<locals>.normalize_dataframe\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m   1155\u001b[0m     data \u001b[39m=\u001b[39m [block\u001b[39m.\u001b[39mvalues \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m mgr\u001b[39m.\u001b[39mblocks]\n\u001b[0;32m   1156\u001b[0m data\u001b[39m.\u001b[39mextend([df\u001b[39m.\u001b[39mcolumns, df\u001b[39m.\u001b[39mindex])\n\u001b[1;32m-> 1157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(normalize_token, data))\n",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\utils.py:640\u001b[0m, in \u001b[0;36mDispatch.__call__\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[39mCall the corresponding method based on type of argument.\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    639\u001b[0m meth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch(\u001b[39mtype\u001b[39m(arg))\n\u001b[1;32m--> 640\u001b[0m \u001b[39mreturn\u001b[39;00m meth(arg, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\base.py:1207\u001b[0m, in \u001b[0;36mregister_numpy.<locals>.normalize_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1203\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1204\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1205\u001b[0m         \u001b[39m# string fast-path\u001b[39;00m\n\u001b[0;32m   1206\u001b[0m         data \u001b[39m=\u001b[39m hash_buffer_hex(\n\u001b[1;32m-> 1207\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(x\u001b[39m.\u001b[39;49mflat)\u001b[39m.\u001b[39mencode(\n\u001b[0;32m   1208\u001b[0m                 encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m, errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1209\u001b[0m             )\n\u001b[0;32m   1210\u001b[0m         )\n\u001b[0;32m   1211\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mUnicodeDecodeError\u001b[39;00m:\n\u001b[0;32m   1212\u001b[0m         \u001b[39m# bytes fast-path\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m         data \u001b[39m=\u001b[39m hash_buffer_hex(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(x\u001b[39m.\u001b[39mflat))\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dgdf = ddf.from_pandas(gdf,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\base.py:1207\u001b[0m, in \u001b[0;36mregister_numpy.<locals>.normalize_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1205\u001b[0m     \u001b[39m# string fast-path\u001b[39;00m\n\u001b[0;32m   1206\u001b[0m     data \u001b[39m=\u001b[39m hash_buffer_hex(\n\u001b[1;32m-> 1207\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(x\u001b[39m.\u001b[39;49mflat)\u001b[39m.\u001b[39mencode(\n\u001b[0;32m   1208\u001b[0m             encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m, errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1209\u001b[0m         )\n\u001b[0;32m   1210\u001b[0m     )\n\u001b[0;32m   1211\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mUnicodeDecodeError\u001b[39;00m:\n\u001b[0;32m   1212\u001b[0m     \u001b[39m# bytes fast-path\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 1989929: expected str instance, NoneType found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\base.py:1216\u001b[0m, in \u001b[0;36mregister_numpy.<locals>.normalize_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1216\u001b[0m     data \u001b[39m=\u001b[39m hash_buffer_hex(pickle\u001b[39m.\u001b[39;49mdumps(x, pickle\u001b[39m.\u001b[39;49mHIGHEST_PROTOCOL))\n\u001b[0;32m   1217\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1218\u001b[0m     \u001b[39m# pickling not supported, use UUID4-based fallback\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dgdf \u001b[39m=\u001b[39m ddf\u001b[39m.\u001b[39;49mfrom_pandas(gdf,\u001b[39m64\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m dgdf[\u001b[39m'\u001b[39m\u001b[39mEnd Date\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m ddf\u001b[39m.\u001b[39mto_datetime(dgdf[\u001b[39m'\u001b[39m\u001b[39mEnd Date\u001b[39m\u001b[39m'\u001b[39m],exact\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,error\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m'\u001b[39m,infer_datetime_format\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\dataframe\\io\\io.py:275\u001b[0m, in \u001b[0;36mfrom_pandas\u001b[1;34m(data, npartitions, chunksize, sort, name)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunksize, \u001b[39mint\u001b[39m):\n\u001b[0;32m    271\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    272\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease provide chunksize as an int, or possibly as None if you specify npartitions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     )\n\u001b[1;32m--> 275\u001b[0m name \u001b[39m=\u001b[39m name \u001b[39mor\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mfrom_pandas-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m tokenize(data, chunksize, npartitions))\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nrows:\n\u001b[0;32m    278\u001b[0m     \u001b[39mreturn\u001b[39;00m new_dd_object({(name, \u001b[39m0\u001b[39m): data}, name, data, [\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m])\n",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\base.py:931\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    923\u001b[0m     \u001b[39m\"\"\"Deterministic token\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \n\u001b[0;32m    925\u001b[0m \u001b[39m    >>> tokenize([1, 2, '3'])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[39m    True\u001b[39;00m\n\u001b[0;32m    930\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 931\u001b[0m     hasher \u001b[39m=\u001b[39m _md5(\u001b[39mstr\u001b[39m(\u001b[39mtuple\u001b[39;49m(\u001b[39mmap\u001b[39;49m(normalize_token, args)))\u001b[39m.\u001b[39mencode())\n\u001b[0;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m kwargs:\n\u001b[0;32m    933\u001b[0m         hasher\u001b[39m.\u001b[39mupdate(\u001b[39mstr\u001b[39m(normalize_token(kwargs))\u001b[39m.\u001b[39mencode())\n",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\utils.py:640\u001b[0m, in \u001b[0;36mDispatch.__call__\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[39mCall the corresponding method based on type of argument.\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    639\u001b[0m meth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch(\u001b[39mtype\u001b[39m(arg))\n\u001b[1;32m--> 640\u001b[0m \u001b[39mreturn\u001b[39;00m meth(arg, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\base.py:1157\u001b[0m, in \u001b[0;36mregister_pandas.<locals>.normalize_dataframe\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m   1155\u001b[0m     data \u001b[39m=\u001b[39m [block\u001b[39m.\u001b[39mvalues \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m mgr\u001b[39m.\u001b[39mblocks]\n\u001b[0;32m   1156\u001b[0m data\u001b[39m.\u001b[39mextend([df\u001b[39m.\u001b[39mcolumns, df\u001b[39m.\u001b[39mindex])\n\u001b[1;32m-> 1157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(normalize_token, data))\n",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\utils.py:640\u001b[0m, in \u001b[0;36mDispatch.__call__\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[39mCall the corresponding method based on type of argument.\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    639\u001b[0m meth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch(\u001b[39mtype\u001b[39m(arg))\n\u001b[1;32m--> 640\u001b[0m \u001b[39mreturn\u001b[39;00m meth(arg, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\base.py:1219\u001b[0m, in \u001b[0;36mregister_numpy.<locals>.normalize_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1216\u001b[0m     data \u001b[39m=\u001b[39m hash_buffer_hex(pickle\u001b[39m.\u001b[39mdumps(x, pickle\u001b[39m.\u001b[39mHIGHEST_PROTOCOL))\n\u001b[0;32m   1217\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1218\u001b[0m     \u001b[39m# pickling not supported, use UUID4-based fallback\u001b[39;00m\n\u001b[1;32m-> 1219\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtokenize.ensure-deterministic\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[0;32m   1220\u001b[0m         data \u001b[39m=\u001b[39m uuid\u001b[39m.\u001b[39muuid4()\u001b[39m.\u001b[39mhex\n\u001b[0;32m   1221\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\U_targyak\\MSC\\VIZUÁLISADATELEMZÉS\\.venv\\lib\\site-packages\\dask\\config.py:492\u001b[0m, in \u001b[0;36mget\u001b[1;34m(key, default, config, override_with)\u001b[0m\n\u001b[0;32m    487\u001b[0m         update(config, d, priority\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mold\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    489\u001b[0m     update(config, collect(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[1;32m--> 492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\n\u001b[0;32m    493\u001b[0m     key: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    494\u001b[0m     default: Any \u001b[39m=\u001b[39m no_default,\n\u001b[0;32m    495\u001b[0m     config: \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m config,\n\u001b[0;32m    496\u001b[0m     override_with: Any \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    498\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[39m    Get elements from global config\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[39m    dask.config.set\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    528\u001b[0m     \u001b[39mif\u001b[39;00m override_with \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with TqdmCallback(desc=\"compute\"):\n",
    "    dgdf['End Date'] = ddf.to_datetime(dgdf['End Date'],exact=False,error='coerce',infer_datetime_format=True)\n",
    "    dgdf['Start Date'] = ddf.to_datetime(dgdf['Start Date'],exact=False,error='coerce',infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ede1f456ae69eb414809088a47924335f16c2aea89e2f0bf6d27a416eba0896e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
